{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform clustering on Olivetti faces dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the dataset and visualise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "faces = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "example_image_num = 20\n",
    "\n",
    "print('Image size', faces['images'][example_image_num].shape)\n",
    "\n",
    "plt.imshow(faces['images'][example_image_num], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Image flatterned shape:\\n', faces['data'][example_image_num].shape)\n",
    "print('\\nImage identifiers:\\n', faces['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the dataset into train & test\n",
    "### Need to shuffle as images are ordered by person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val_test, y_train, y_val_test = train_test_split(faces['data'], \n",
    "                                                            faces['target'], \n",
    "                                                            test_size=0.2,\n",
    "                                                            stratify=faces['target'])\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_val_test, \n",
    "                                                y_val_test, \n",
    "                                                test_size=0.5,\n",
    "                                                stratify=y_val_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the dataset\n",
    "### Choose the best number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "clusters = np.arange(10, 300, 30)\n",
    "inertias = []\n",
    "silhouettes = []\n",
    "\n",
    "for cluster in clusters:\n",
    "    kmc = KMeans(n_clusters=cluster)\n",
    "    kmc.fit(X_train)\n",
    "    inertias.append(kmc.inertia_)\n",
    "    silhouettes.append(silhouette_score(X_train, kmc.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters, inertias)\n",
    "plt.xlabel('# clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.grid(which='both')\n",
    "plt.title('# clusters choice from inertia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(clusters, silhouettes)\n",
    "plt.xlabel('# clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.grid(which='both')\n",
    "plt.title('# clusters choice from silhouettes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re train the model using the best cluster number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc = KMeans(clusters[np.argmax(silhouettes)])\n",
    "kmc.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_cluster_index = 30\n",
    "\n",
    "for flat_image in X_train[np.where(kmc.labels_ == a_cluster_index)]:\n",
    "    plt.imshow(flat_image.reshape(64, 64), cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lrc = LogisticRegression()\n",
    "lrc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use kmeans for dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use kmeans to find distance to cluster centers, then use logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('clustering', KMeans(clusters[np.argmax(silhouettes)])),\n",
    "    ('log_reg', LogisticRegression())    \n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a search over number of clusters to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'clustering__n_clusters': np.arange(10, 150, 30)}\n",
    "grid_clf = GridSearchCV(pipeline, param_grid, cv=3)\n",
    "grid_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid_clf.best_params_)\n",
    "grid_clf.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the cluster distances to the feature set & retrain\n",
    "\n",
    "## STILL TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_2 = Pipeline([\n",
    "    ('predict_cluster', KMeans(clusters[np.argmax(silhouettes)])),\n",
    "    ('log_reg', LogisticRegression()) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_cluster_dist = np.c_[X_train, pipeline['clustering'].labels_]\n",
    "X_train_with_cluster_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc = LogisticRegression()\n",
    "lrc.fit(X_train_with_cluster_dist, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
