{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST classification using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(X_train_full, y_train_full), (X_test_full, y_test_full) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a validation set & scale the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train\n",
      "(50000, 28, 28) float32\n",
      "(50000,) int8\n",
      "\n",
      "Val\n",
      "(10000, 28, 28) float32\n",
      "(10000,) int8\n",
      "\n",
      "Test\n",
      "(10000, 28, 28) float32\n",
      "(10000,) int8\n",
      "\n",
      "Max values:\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "boundary = 50000\n",
    "scale = 255.0\n",
    "\n",
    "X_train = (X_train_full[:boundary]/scale).astype(np.float32)\n",
    "y_train = y_train_full[:boundary].astype(np.int8)\n",
    "\n",
    "X_val = (X_train_full[boundary:]/scale).astype(np.float32)\n",
    "y_val = y_train_full[boundary:].astype(np.int8)\n",
    "\n",
    "X_test = (X_test_full / scale).astype(np.float32)\n",
    "y_test = y_test_full.astype(np.int8)\n",
    "\n",
    "print('\\nTrain')\n",
    "print(X_train.shape, X_train.dtype)\n",
    "print(y_train.shape, y_train.dtype)\n",
    "\n",
    "print('\\nVal')\n",
    "print(X_val.shape, X_val.dtype)\n",
    "print(y_val.shape, y_val.dtype)\n",
    "\n",
    "print('\\nTest')\n",
    "print(X_test.shape, X_test.dtype)\n",
    "print(y_test.shape, y_test.dtype)\n",
    "\n",
    "print('\\nMax values:')\n",
    "print(X_train.max())\n",
    "print(X_val.max())\n",
    "print(X_test.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                3010      \n",
      "=================================================================\n",
      "Total params: 419,110\n",
      "Trainable params: 419,110\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_neurons = 300\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=X_train.shape[1:]))\n",
    "model.add(keras.layers.Dense(num_neurons, activation='relu'))\n",
    "model.add(keras.layers.Dense(num_neurons, activation='relu'))\n",
    "model.add(keras.layers.Dense(num_neurons, activation='relu'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax')) # predict prob of being of class\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.SGD(lr=0.05),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')  # Specify where to store the log files\n",
    "\n",
    "def get_run_log_dir(logdir):\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')  # Use the date/time so all logs are kept\n",
    "    return os.path.join(logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('best_mnist_model.h5', save_best_only=True)\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(get_run_log_dir(root_logdir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 0.0085 - accuracy: 0.9980 - val_loss: 0.2085 - val_accuracy: 0.9461\n",
      "Epoch 2/30\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 0.0064 - accuracy: 0.9985 - val_loss: 0.0888 - val_accuracy: 0.9784\n",
      "Epoch 3/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0856 - val_accuracy: 0.9799\n",
      "Epoch 4/30\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0805 - val_accuracy: 0.9809\n",
      "Epoch 5/30\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0834 - val_accuracy: 0.9810\n",
      "Epoch 6/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9811\n",
      "Epoch 7/30\n",
      "50000/50000 [==============================] - 5s 104us/sample - loss: 9.0755e-04 - accuracy: 1.0000 - val_loss: 0.0850 - val_accuracy: 0.9808\n",
      "Epoch 8/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 7.8217e-04 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 0.9803\n",
      "Epoch 9/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 6.8468e-04 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9809\n",
      "Epoch 10/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 6.1480e-04 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9814\n",
      "Epoch 11/30\n",
      "50000/50000 [==============================] - 5s 104us/sample - loss: 5.4930e-04 - accuracy: 1.0000 - val_loss: 0.0881 - val_accuracy: 0.9810\n",
      "Epoch 12/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 4.9778e-04 - accuracy: 1.0000 - val_loss: 0.0891 - val_accuracy: 0.9809\n",
      "Epoch 13/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 4.5219e-04 - accuracy: 1.0000 - val_loss: 0.0898 - val_accuracy: 0.9812\n",
      "Epoch 14/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 4.1627e-04 - accuracy: 1.0000 - val_loss: 0.0908 - val_accuracy: 0.9810\n",
      "Epoch 15/30\n",
      "50000/50000 [==============================] - 5s 102us/sample - loss: 3.8628e-04 - accuracy: 1.0000 - val_loss: 0.0917 - val_accuracy: 0.9814\n",
      "Epoch 16/30\n",
      "50000/50000 [==============================] - 5s 104us/sample - loss: 3.5917e-04 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9811\n",
      "Epoch 17/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 3.3599e-04 - accuracy: 1.0000 - val_loss: 0.0928 - val_accuracy: 0.9812\n",
      "Epoch 18/30\n",
      "50000/50000 [==============================] - 5s 105us/sample - loss: 3.1662e-04 - accuracy: 1.0000 - val_loss: 0.0937 - val_accuracy: 0.9809\n",
      "Epoch 19/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 2.9878e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9811\n",
      "Epoch 20/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 2.8445e-04 - accuracy: 1.0000 - val_loss: 0.0940 - val_accuracy: 0.9812\n",
      "Epoch 21/30\n",
      "50000/50000 [==============================] - 5s 104us/sample - loss: 2.6870e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9812\n",
      "Epoch 22/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 2.5502e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9814\n",
      "Epoch 23/30\n",
      "50000/50000 [==============================] - 5s 103us/sample - loss: 2.4398e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9810\n",
      "Epoch 24/30\n",
      "50000/50000 [==============================] - 5s 107us/sample - loss: 2.3336e-04 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9815\n",
      "Epoch 25/30\n",
      "50000/50000 [==============================] - 6s 117us/sample - loss: 2.2333e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9811\n",
      "Epoch 26/30\n",
      "50000/50000 [==============================] - 5s 106us/sample - loss: 2.1364e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9813\n",
      "Epoch 27/30\n",
      "50000/50000 [==============================] - 5s 101us/sample - loss: 2.0462e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9816\n",
      "Epoch 28/30\n",
      "50000/50000 [==============================] - 5s 98us/sample - loss: 1.9607e-04 - accuracy: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9813\n",
      "Epoch 29/30\n",
      "50000/50000 [==============================] - 5s 97us/sample - loss: 1.8913e-04 - accuracy: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9815\n",
      "Epoch 30/30\n",
      "50000/50000 [==============================] - 5s 95us/sample - loss: 1.8126e-04 - accuracy: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9814\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=30, \n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model (including weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'mnist_keras_model.h5'\n",
    "\n",
    "model.save(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model (including weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_mnist_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01641685505398549, 0.99536]\n",
      "[0.07758548712676856, 0.9784]\n",
      "[0.06852413096951786, 0.9782]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(X_train, y_train, verbose=0))\n",
    "print(model.evaluate(X_val, y_val, verbose=0))\n",
    "print(model.evaluate(X_test, y_test, verbose=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
