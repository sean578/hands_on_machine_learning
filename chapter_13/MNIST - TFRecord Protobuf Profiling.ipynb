{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the MNIST dataset and split into train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(50000, 10)\n",
      "(10000, 10)\n",
      "uint8\n",
      "float32\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "boundary = 50000\n",
    "num_classes = 10\n",
    "\n",
    "X_train = train_images[:boundary, :, :]\n",
    "y_train = to_categorical(train_labels[:boundary], num_classes=num_classes)\n",
    "\n",
    "X_val = train_images[boundary:, :, :]\n",
    "y_val = to_categorical(train_labels[boundary:], num_classes=num_classes)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "\n",
    "print(X_train.dtype)\n",
    "print(y_train.dtype)\n",
    "\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shuffle the training data\n",
    "### Use the Tensorflow dataset API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "shuffle_seed = 47\n",
    "buffer_size = 100\n",
    "\n",
    "X_train_shuffled = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size=buffer_size, \n",
    "                                                                       seed = shuffle_seed)\n",
    "y_train_shuffled = tf.data.Dataset.from_tensor_slices(y_train).shuffle(buffer_size=buffer_size, \n",
    "                                                                       seed = shuffle_seed)\n",
    "\n",
    "for image in X_train_shuffled.take(1):\n",
    "    plt.imshow(image)\n",
    "for label in y_train_shuffled.take(1):\n",
    "    print(label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the data using TensorFlow protobufs and TFRecord files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the image & label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of serialized train images =  50000\n",
      "# of serialized train labels =  50000\n",
      "# of serialized val images =  10000\n",
      "# of serialized val labels =  10000\n"
     ]
    }
   ],
   "source": [
    "def serialize_tensors(X):\n",
    "    X_serial = []\n",
    "    for x in X:\n",
    "        X_serial.append(tf.io.serialize_tensor(tensor = x))\n",
    "    return X_serial\n",
    "    \n",
    "###############################################\n",
    "\n",
    "X_train_serial = serialize_tensors(X_train_shuffled)\n",
    "X_val_serial = serialize_tensors(X_val)\n",
    "y_train_serial = serialize_tensors(y_train_shuffled)\n",
    "y_val_serial = serialize_tensors(y_val)\n",
    "\n",
    "print('# of serialized train images = ', len(X_train_serial))\n",
    "print('# of serialized train labels = ', len(y_train_serial))\n",
    "\n",
    "print('# of serialized val images = ', len(X_val_serial))\n",
    "print('# of serialized val labels = ', len(y_val_serial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the protobufs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v2.train import Feature, Features, Example, BytesList\n",
    "import numpy as np\n",
    "\n",
    "# Only the numpy array of the tensor is saved to file --> lose all other tensor info\n",
    "\n",
    "def create_protobuf_X_and_y(X_serial, y_serial, X_shape, y_shape):\n",
    "\n",
    "    X_as_bytes = []\n",
    "    y_as_bytes = []\n",
    "    X_shape_as_bytes = [] \n",
    "    y_shape_as_bytes = []\n",
    "    for X, y in zip(X_serial, y_serial):\n",
    "        X_as_bytes.append(BytesList(value=[X.numpy()])) # Convert image to bytes list\n",
    "        y_as_bytes.append(BytesList(value=[y.numpy()])) # Convert label to bytes list\n",
    "        X_shape_as_bytes.append(BytesList(value=[X_shape.numpy()]))\n",
    "        y_shape_as_bytes.append(BytesList(value=[y_shape.numpy()]))\n",
    "        \n",
    "    protobuf_data = []\n",
    "    for X, y, X_shape, y_shape in zip(X_as_bytes, y_as_bytes, X_shape_as_bytes, y_shape_as_bytes):\n",
    "        protobuf_data.append(Example(\n",
    "            features = Features(\n",
    "                feature={\n",
    "                    'X': Feature(bytes_list = X),\n",
    "                    'y': Feature(bytes_list = y),\n",
    "                    'X_shape': Feature(bytes_list = X_shape),\n",
    "                    'y_shape': Feature(bytes_list = y_shape)\n",
    "                }\n",
    "            )\n",
    "        ))\n",
    "        \n",
    "    return protobuf_data\n",
    "X_shape = tf.io.serialize_tensor(tensor = [28, 28])\n",
    "y_shape = tf.io.serialize_tensor(tensor = [10])\n",
    "\n",
    "protobuf_data_train = create_protobuf_X_and_y(X_train_serial, \n",
    "                                              y_train_serial, \n",
    "                                              X_shape, \n",
    "                                              y_shape)\n",
    "\n",
    "protobuf_data_val = create_protobuf_X_and_y(X_val_serial, \n",
    "                                              y_val_serial, \n",
    "                                              X_shape, \n",
    "                                              y_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write the records to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tf_records(filename, data):\n",
    "    with tf.io.TFRecordWriter(filename) as f:\n",
    "        for d in data:\n",
    "            f.write(d.SerializeToString())\n",
    "            \n",
    "write_tf_records('train.tfrecord', protobuf_data_train)\n",
    "write_tf_records('val.tfrecord', protobuf_data_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the records from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fn(data_record):\n",
    "    \n",
    "    feature_description = {\n",
    "    'X': tf.io.FixedLenFeature([], tf.string),\n",
    "    'y': tf.io.FixedLenFeature([], tf.string),\n",
    "    'X_shape': tf.io.FixedLenFeature([], tf.string),\n",
    "    'y_shape': tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    return tf.io.parse_single_example(data_record, feature_description)\n",
    "\n",
    "dataset_train = tf.data.TFRecordDataset(['train.tfrecord'])\n",
    "dataset_train = dataset_train.map(extract_fn) # Strings of numpy data for x, y\n",
    "\n",
    "dataset_val = tf.data.TFRecordDataset(['val.tfrecord'])\n",
    "dataset_val = dataset_val.map(extract_fn) # Strings of numpy data for x, y\n",
    "\n",
    "def create_image_label_pairs(data_record):\n",
    "    \n",
    "    X = tf.io.parse_tensor(data_record['X'], out_type=tf.uint8)\n",
    "    y = tf.io.parse_tensor(data_record['y'], out_type=tf.float32)\n",
    "    X_shape = tf.io.parse_tensor(data_record['X_shape'], out_type=tf.float32)\n",
    "    y_shape = tf.io.parse_tensor(data_record['y_shape'], out_type=tf.float32)\n",
    "    \n",
    "    # TODO: Get the shapes out of the TFRecord so can use them here\n",
    "    \n",
    "    X.set_shape((28,28))\n",
    "    y.set_shape((10))\n",
    "    \n",
    "    return (X, y)\n",
    "        \n",
    "dataset_train_tuple = dataset_train.map(create_image_label_pairs) # Create tuples of image, label tensors\n",
    "dataset_val_tuple = dataset_val.map(create_image_label_pairs) # Create tuples of image, label tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.Dense(30, activation='relu', kernel_initializer='glorot_uniform'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 30)                23550     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 24,790\n",
      "Trainable params: 24,790\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 1.6102 - accuracy: 0.5346 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9603 - accuracy: 0.6143 - val_loss: 0.8976 - val_accuracy: 0.6245\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.9219 - accuracy: 0.6229 - val_loss: 0.9193 - val_accuracy: 0.6186\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.9025 - accuracy: 0.6294 - val_loss: 0.8696 - val_accuracy: 0.6303\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.8796 - accuracy: 0.6382 - val_loss: 0.8231 - val_accuracy: 0.6616\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7579 - accuracy: 0.7161 - val_loss: 0.6789 - val_accuracy: 0.7268\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.7143 - accuracy: 0.7259 - val_loss: 0.6708 - val_accuracy: 0.7293\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6691 - accuracy: 0.7324 - val_loss: 0.7020 - val_accuracy: 0.7096\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6533 - accuracy: 0.7339 - val_loss: 0.6979 - val_accuracy: 0.7173\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.6598 - accuracy: 0.7352 - val_loss: 0.6606 - val_accuracy: 0.7271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f273c0ae8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset_train_tuple.batch(32), \n",
    "          validation_data=dataset_val_tuple.batch(32), \n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
